---
title: AI人工智能基础
synonym: [人工智能, 人工智慧]
tag: [机器学习, 神经网络, 深度学习, 知识图谱]
---



# AI

> `Technical Principles`, `Fundametals`
>
> 技术原理, 基本原理, 核心逻辑, 核心思想

## Resources

- 

## 认知

- AI Engineers are the architects behind practical AI application
  
- Handle development to deployment of Al systems
  
  

## 应用前景

## Quickstart

> [!Note]
>
> > 深度学习模型训练流程, 需要哪些前置知识和技术以及框架?
>
> 在进行深度学习模型的训练之前，需要掌握一系列前置知识和技术以及使用合适的框架。以下是一些关键的前置知识和技术
>
> 数学基础 (Mathematics)
>
> 
>
> •**线性代数 (Linear Algebra)**: 矩阵运算、特征向量、特征值等是深度学习的核心。
>
> •**微积分 (Calculus)**: 梯度计算、链式法则在反向传播算法中非常重要。
>
> ​	•	**概率论与统计学 (Probability and Statistics)**: 概率分布、贝叶斯定理、假设检验等有助于理解模型的输出和不确定性。
>
> ​	•	**优化理论 (Optimization Theory)**: 梯度下降算法、学习率、损失函数等优化问题的概念是训练模型的核心部分。
>
> 
>
> **2. 编程语言和工具 (Programming Languages and Tools)**
>
> 
>
> ​	•	**Python**: 深度学习框架（如TensorFlow、PyTorch）的首选编程语言，掌握基础编程、数据结构和面向对象编程。
>
> ​	•	**NumPy/Pandas**: 数据处理和分析工具，方便进行矩阵运算和数据预处理。
>
> ​	•	**Jupyter Notebooks**: 用于数据探索、实验记录和模型训练的环境，特别适合可视化和调试。
>
> 
>
> **3. 机器学习基础 (Machine Learning Basics)**
>
> 
>
> ​	•	**监督学习/无监督学习 (Supervised/Unsupervised Learning)**: 需要掌握基本的学习类型和训练流程。
>
> ​	•	**过拟合和欠拟合 (Overfitting and Underfitting)**: 理解模型训练过程中如何控制模型的复杂度。
>
> ​	•	**交叉验证和超参数优化 (Cross-validation and Hyperparameter Tuning)**: 模型评估和参数调整是训练中关键的步骤。
>
> 
>
> **4. 深度学习基础 (Deep Learning Basics)**
>
> 
>
> ​	•	**神经网络基础 (Neural Networks Basics)**: 了解神经网络的结构、激活函数（如ReLU、Sigmoid）、损失函数和权重更新。
>
> ​	•	**反向传播 (Backpropagation)**: 理解如何通过反向传播算法计算梯度并更新网络参数。
>
> ​	•	**常见网络架构 (Common Architectures)**: 如卷积神经网络（CNN）用于图像处理，循环神经网络（RNN）用于序列数据。
>
> 
>
> **5. 深度学习框架 (Deep Learning Frameworks)**
>
> 
>
> ​	•	**TensorFlow**: Google开发的开源深度学习框架，具有高度的灵活性和可扩展性。
>
> ​	•	**PyTorch**: Facebook开发的框架，以易于使用和动态计算图著称，广泛用于学术界和工业界。
>
> ​	•	**Keras**: 基于TensorFlow的高层次神经网络API，简化了模型构建过程，适合快速原型开发。
>
> 
>
> **6. GPU加速与分布式计算 (GPU Acceleration and Distributed Computing)**
>
> 
>
> ​	•	**CUDA和cuDNN**: 使用NVIDIA GPU进行模型加速的基础工具，提升训练效率。
>
> ​	•	**分布式计算 (Distributed Computing)**: 在多个GPU或集群上并行训练大规模深度学习模型的能力。
>
> 
>
> **7. 数据预处理与增强 (Data Preprocessing and Augmentation)**
>
> 
>
> ​	**数据清洗和归一化 (Data Cleaning and Normalization)**: 处理缺失数据、异常值以及特征标准化。
>
> ​	•**数据增强 (Data Augmentation)**: 在训练数据不足的情况下，使用旋转、缩放等技术生成更多数据。
>
> 
>
> **8. 模型部署 (Model Deployment)**
>
> 
>
> ​	•**ONNX和TensorRT**: 将模型转换为可在不同平台上运行的格式，用于推理和优化。
>
> ​	•	**Flask/FastAPI**: 用于构建API，将深度学习模型部署为Web服务。
>
> 
>
> **推荐的学习路径:**
>
> 
>
> ​	1.	学习基础数学和编程。
>
> ​	2.	熟悉机器学习基础理论，尝试构建简单的机器学习模型。
>
> ​	3.	掌握深度学习框架的使用（如TensorFlow、PyTorch）。
>
> ​	4.	实践各种深度学习任务（如图像分类、文本生成等）。

### 核心概念

GPT是一种基于深度学习的自然语言处理技术，利用了大规模数据集进行预训练，以生成文本。它基于Transformer架构，这是一种专为处理序列数据（如文本）设计的深度学习模型架构。GPT的核心特性包括：

- **自注意力机制**：Transformer架构的关键，允许模型在处理每个词时考虑到整个文本序列，从而捕捉复杂的语言关系。
- **预训练与微调**：GPT先在大规模数据集上进行预训练，学习语言模式和知识，然后可以针对特定任务进行微调，以提高性能。
- **生成能力**：GPT能够基于给定的文本提示生成连贯、相关的文本，使其应用于各种场景，包括文本生成、摘要、翻译等。

**自注意力机制**





# Glossary

> 相关文档
>

## Links

- [Nvidia Glossary](https://www.nvidia.com/en-us/glossary/)
- [AWS What is](https://aws.amazon.com/what-is/)
- [Cloudflare Learning](https://www.cloudflare.com/learning/)
- 

## Lists

- 偏置(bias)
- 权重(weight)
- 方差**方差 (Variance)**:
- 拟合(fit)
    - 过拟合
    - 欠拟合

- 神经网络(neural network):
    - 卷积神经网络
    - CNN 图像识别
    - RNN NLP领域
- 机器学习(Machine Learning): 
- 深度学习
- 迁移学习
- 强化学习
- 监督学习(supervised learning)
- 无监督学习
- 对比学习
- **模型**(model)
    - [[Microsoft](https://learn.microsoft.com/zh-cn/windows/ai/windows-ml/what-is-a-machine-learning-model)]机器学习模型是一个文件，在经过训练后可以识别特定类型的模式。 你可以用一组数据训练模型，为它提供一种算法，模型利用该算法学习这些数据并进行推理。
    - 表示一个知识, 数据的结构
    - **模型**是机器学习中用来预测或分类的数学结构，它定义了输入与输出之间的映射关系。模型可以是线性的，也可以是复杂的非线性结构，如深度神经网络。
    - 模型是一种数学函数或计算框架, 模型决定了输入到输出的过程
    - 模型是一种简化. 它是对现实时间的解释——把与解决问题密切相关的方面抽象出来, 而忽略无关的细节. 
- 大语言模型(Large Language Models, LLM)
    - [Nvidia LLM](https://www.nvidia.com/en-us/glossary/large-language-models/)
    - [Cloudflare LLM](https://www.cloudflare.com/learning/ai/what-is-large-language-model/)
- 生成式AI(Generative AI, GenAI)
    - [GenAI](https://aws.amazon.com/what-is/generative-ai/)
- 损失函数(Loss Fuction)
- 优化算法
    - **梯度下降法（Gradient Descent）**
- **激活函数**(Activate Function)
- 监督学习
- 无监督学习
- 迁移学习(transfer learning)
- 参数
- 算法
- 训练(Train)
- 推理(infer/reasoning)
- 评估(Evaluate)
- 预测(Predict)
- 分类(classification, classify)
- 提示(Prompt): 提示词
- 思维链(Chain-of-Thought, CoT)
- 思维树(Tree-of-Thoughts, ToT)
- 标量(scalar)
- 向量(vector)
- 矩阵(matrix)
- 卷积(convolution)
- 
- transformer
- attention
- GPT(Generative Pre-trained Transformers):生成式预训练转换器
    - 生成式 预训练 自注意力转换器
- GenAI(Generative Artifical Intelligenc)—生成式人工智能
- AGI(Artificial General Intelligence)—通用人工智能
- 梯度(gradient)
- CoT(Chain of Thought)——思维链
- GoT(Graph of Thought)——思维图

## Lingo

### universal

- Lora
  - LoRA（Low-Rank Adaptation）是一种用于大型神经网络模型的参数高效调整技术
    - 低秩适应

  - LoRA: Low-Rank Adaptation of Large Language Models
  - [LoRA: Low-Rank Adaptation of Large Language Models](https://arxiv.org/abs/2106.09685)
  - 作用
    - 将生活中的角色和风格带入到AI中, 起到扩充的效果
    - However, if you have ever wanted to generate an image of a well-known character, concept, or using a specific style, you might've been disappointed with the results. **It's common that Stable Diffusion's powerful AI doesn't do a good job at bringing characters and styles to life by itself.** Luckily, LoRA models can help with this problem.

  - 参考资料
    - [Stable Diffusion: What Are LoRA Models and How to Use Them?](https://softwarekeep.com/help-center/how-to-use-stable-diffusion-lora-models)

- **VAE**(Variational Autoencoder)--变分自编码器

    - 学习数据分布的生成模型，适用于各种生成和重构任务。

- **RAG**(Retrieval-Augmented Generation): 检索增强生成
  
  - https://blogs.nvidia.com/blog/what-is-retrieval-augmented-generation/
  - RAG is an AI framework for retrieving facts from an external knowledge base to ground large language models (LLMs) on the most accurate, up-to-date information and to give users insight into LLMs' generative process.——[IBM: What is retrieval-augmented generation?](https://research.ibm.com/blog/retrieval-augmented-generation-RAG)
  - RAG is a technique for augmenting LLM knowledge with additional data.
  
- fine-tuning(微调)

- ONNX

- **CLIP**(Contrastive Language–Image Pretraining)-对比语言图像预训练

  - https://github.com/OpenAI/CLIP
  - 理解图像和文本之间的关联, 适用于多模态学习任务
  - 用来打标
  - 是一种神经网络
  - **unCLIP**

- **UNet**(Convolutional Networks for Biomedical Image Segmentation)

    - 主要用于图像分割任务, 语义分割
    - **U-Net**是[弗赖堡大学](https://zh.wikipedia.org/wiki/弗赖堡大学)计算机科学系为生物医学[图像分割](https://zh.wikipedia.org/wiki/图像分割)开发的[卷积神经网络](https://zh.wikipedia.org/wiki/卷积神经网络)。
    - 图像分割设计的有效网络

- Zero-shot Learning(零迁移学习)

- Generative Agents(生成式智能体)
  - https://mp.weixin.qq.com/s/y8_Q8X8Qn9ZTxq_R_YMLjg
  - https://arxiv.org/abs/2304.03442

- SAM(分割一切模型)

- GAN

- Transformer(自注意力模型)

- Sampler(采样器)

- step(步数)

- seed(种子)

  - 噪声种子
  - 起点

- latent diffusion model(潜在扩散模型)

- Latent Space(潜空间, **潜在空间**)

  - Manifold_hypothesis

- U-Net model()

- cfg scale(提示词 强度)
    - 图像的一致性参数

    - 提示词引导系数

    - 数值较低时, 生成更自由, 

    - 数值较高时, 生成结果更贴合输入提示, 生成的

    - *Kayn: 类似提示词强度*

- classifier-free guidance (CFG) 

- Noise(噪音, 噪声)

- 前向扩散

- 逆向扩散

- 幻觉(hallucinate

- SOTA(State of the Art): 技术前沿, 最先进水平,顶尖水平

  - **SOTA** 的英文全称是 **State of the Art**，意思是“技术前沿”或“最先进水平”。在人工智能和机器学习领域，SOTA 指的是当前在某个特定任务或基准上达到了最高性能的模型或算法。


### sd

- 重绘幅度

### Agent

Autonomous agents 又被称为智能体Agent。能够通过感知周围环境、进行规划以及执行动作来完成既定任务。在这些能力中，规划尤为重要，它涉及到复杂的理解、推理和决策制定。

Intelligent agent(智能代理)

**Artificial Intelligence Agent**(人工只能代理)

“agent” 的核心概念是指一种能够自主感知、决策和行动的系统。



> Agent的核心决策机制围绕着动态适应与持续优化展开。它使LLM（大型语言模型）能够依据实时变动的环境信息，灵活选择并执行恰当的行动策略，或对行动结果进行精准评估与判断。这一过程通过多轮迭代不断重复，每一次迭代都基于对环境的深入理解与上一次执行效果的反馈，旨在逐步逼近并最终达成既定目标。Agent的此种运作模式，确保了其在复杂多变的环境中能够保持高效、灵活与适应性，持续推动任务向成功迈进。
>
> 
>
> 
>
> **精简的决策流程：**P（感知）→ P（规划）→ A（行动）
>
> 1. 感知（Perception）是指Agent从环境中收集信息并从中提取相关知识的能力。
> 2. 规划（Planning）是指Agent为了某一目标而作出的决策过程。
> 3. 行动（Action）是指基于环境和规划做出的动作。

## 深度学习

- IPAdapter(图像提示适配器, Image Prompt Adapter)

## LLM

## data

ETL (Extract, Transform, Load) 的解释

抽取 转换, 加载

ETL 是 **数据集成（Data Integration）** 的核心流程，用于从各种数据源中抽取数据、转换为目标格式，然后加载到最终目标系统（如数据仓库或数据库）。这是数据工程中常见的操作流程，特别是在 **数据仓库（Data Warehouse）** 和 **数据分析** 场景中被广泛应用。

- 数据工程

## Items

### 模型(model)

> [!note]
>
> 在计算机科学中, 当我们提到 **"模型"** 时, 通常指的是一个用来从数据中学习并进行预测的数学或统计工具, 而最常见的具体实现形式就是 **神经网络模型**。

**数学函数 (Mathematical Function)**: 模型本质上是一个数学函数, 它接受输入并产生输出。通过调整函数的参数 (Parameters), 我们可以使模型更好地适应数据, 提高预测准确性。

**神经网络 (Neural Network)**: 在深度学习中, 模型通常由多层 **神经元 (Neurons)** 组成, 模拟人脑的结构和工作方式。每一层从前一层获取信息, 经过处理后传递给下一层, 最终输出结果。这种层层传递和处理信息的方式使模型能够学习和捕捉数据中的复杂模式和特征。

### 神经网络(Neural Network)

> [!note]
> 多维认知
> 

> 神经网络的核心组件包括： 
> 层：线性层、卷积层、循环层等。

激活函数：ReLU、Sigmoid、Softmax 等。

损失函数：MSE、交叉熵等。

优化器：SGD、Adam 等。

正则化：L2 正则化、Dropout 等。

初始化方法：Xavier、He 初始化等。

反向传播：训练神经网络的核心算法。

数据预处理：归一化、标准化、数据增强等。

### 知识图谱(knowledge graph)

#### 多维定义

- [华为云知识-人工智能知识图谱](https://www.huaweicloud.com/zhishi/smart-18528947.html): 知识图谱是一种用于组织和表示结构化知识的图形[ 数据库 ](https://www.huaweicloud.com/product/gaussdb.html)模型，它将现实世界中的事物、概念、关系等信息以图形的形式进行建模，并使用图形数据库技术来存储和查询这些数据。

### 机器学习

#### 多维定义

- 机器学习是从**数据**中**自动分析获得模型**，并利用**模型**对未知数据进行预测。(人工智能讲义)
- Most machine learning workflows involve working with data, creating models, optimizing model parameters, and saving the trained models. This tutorial introduces you to a complete ML workflow implemented in PyTorch, with links to learn more about each of these concepts.
  - 大多数机器学习工作流程涉及到数据处理, 模型创建, 模型参数微调和预训练模型保存.


### 张量Tensor

> Tensors are a specialized data structure that are very similar to arrays and matrices. In PyTorch, we use tensors to encode the inputs and outputs of a model, as well as the model’s parameters.
>
> Tensors are similar to [NumPy’s](https://numpy.org/) ndarrays, except that tensors can run on GPUs or other hardware accelerators. In fact, tensors and NumPy arrays can often share the same underlying memory, eliminating the need to copy data (see [Bridge with NumPy](https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html#bridge-to-np-label)). Tensors are also optimized for automatic differentiation (we’ll see more about that later in the [Autograd](https://pytorch.org/tutorials/beginner/basics/autogradqs_tutorial.html) section). If you’re familiar with ndarrays, you’ll be right at home with the Tensor API. If not, follow along!
>
> ```
> import torch
> import numpy as np
> ```

```text
Tensors are a specialized data structure that are very similar to arrays and matrices. In PyTorch, we use tensors to encode the inputs and outputs of a model, as well as the model’s parameters.
```



### Markov model

马尔科夫模型, 马尔科夫链(Markov Chain)

#### 应用场景

- 语音识别
- 预测

### 卷积神经网络

- Convolutional Neural Network (CNN) - Convolutional Neural Networks are Neural Networks that make the explicit assumption that the inputs are 1d, 2d or multi-dimensional arrays. This assumption allows us to simplify the neural network architecture and make it more efficient for applications in computer vision that use images or video.

### Token

[Microsoft: What are Tokens?](https://learn.microsoft.com/en-us/semantic-kernel/prompt-engineering/tokens)

#### 多维解释

- Tokens: basic units of text/code for LLM AI models to process/generate language.——
  Token: LLM AI模型中文本或代码的基础单元, token用于处理/生成语言. 

#### 附加概念

- Tokenization: splitting input/output texts into smaller units for LLM AI models.

### 回归

> [!tip]
>
> 在人工智能和机器学习领域，回归问题（Regression）是一类主要任务，旨在预测一个连续数值变量的输出。回归问题与分类问题相对，分类问题预测的是离散标签或类别，而回归问题预测的是连续的数值。以下是对回归问题的详解：
>
> ## 回归问题的定义
>
> 回归问题指的是给定一组输入变量 \( X \) 和一个连续输出变量 \( y \)，学习一个映射函数 \( f \)，使得对新的输入数据 \( X' \) 能够准确预测对应的输出 \( y' \)。换句话说，回归问题旨在寻找输入变量与连续目标变量之间的关系。
>
> ## 常见的回归算法
>
> ### 1. 线性回归（Linear Regression）
> 线性回归是最简单的回归算法之一，假设目标变量 \( y \) 与输入变量 \( X \) 之间是线性关系。其模型形式为：
>
> \[ y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \cdots + \beta_n x_n + \epsilon \]
>
> 其中，\( \beta_0, \beta_1, \cdots, \beta_n \) 是模型的参数，\( \epsilon \) 是误差项。
>
> ### 2. 多项式回归（Polynomial Regression）
> 多项式回归是线性回归的扩展，通过增加输入变量的多项式项来捕捉非线性关系。例如，二次多项式回归的形式为：
>
> \[ y = \beta_0 + \beta_1 x + \beta_2 x^2 + \epsilon \]
>
> ### 3. 决策树回归（Decision Tree Regression）
> 决策树回归使用树状结构对数据进行分割，通过逐层分割输入空间来进行预测。每个叶节点代表一个预测值。
>
> ### 4. 支持向量回归（Support Vector Regression, SVR）
> 支持向量回归基于支持向量机（SVM）的概念，通过最大化间隔来找到一个平滑的预测函数。
>
> ### 5. 神经网络回归（Neural Network Regression）
> 神经网络回归通过多个神经元和层的非线性组合来捕捉复杂的输入与输出关系。
>
> ## 回归问题的应用场景
>
> - **房价预测**：根据房子的特征（面积、位置、房间数量等）预测房子的价格。
> - **股票价格预测**：基于历史数据和其他相关因素预测股票的未来价格。
> - **销售预测**：根据历史销售数据和市场趋势预测未来的销售额。
> - **气温预测**：根据历史气象数据预测未来的气温变化。
>
> ## 回归问题的评价指标
>
> 为了评估回归模型的性能，常用以下评价指标：
>
> - **均方误差（Mean Squared Error, MSE）**：衡量预测值与真实值之间差异的平方和的平均值。
>
> \[ MSE = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2 \]
>
> $$R2=1−∑i=1n(yi−yˉ)2∑i=1n(yi−y^i)2$$
>
> 
>
> - **均方根误差（Root Mean Squared Error, RMSE）**：MSE 的平方根，保持与原始数据相同的量纲。
>
> \[ RMSE = \sqrt{MSE} \]
>
> - **平均绝对误差（Mean Absolute Error, MAE）**：衡量预测值与真实值之间绝对差异的平均值。
>
> \[ MAE = \frac{1}{n} \sum_{i=1}^{n} |y_i - \hat{y}_i| \]
>
> - **R²（决定系数）**：反映模型解释变量方差的比例，值在 0 到 1 之间，越接近 1 表示模型越好。
>
> \[ R^2 = 1 - \frac{\sum_{i=1}^{n} (y_i - \hat{y}_i)^2}{\sum_{i=1}^{n} (y_i - \bar{y})^2} \]
>
> ## 实际示例（使用 Python 和 scikit-learn）
>
> 以下是一个使用线性回归进行房价预测的简单示例：
>
> ```python
> import numpy as np
> import pandas as pd
> from sklearn.model_selection import train_test_split
> from sklearn.linear_model import LinearRegression
> from sklearn.metrics import mean_squared_error, r2_score
> 
> # 加载数据集
> data = pd.read_csv('housing.csv')
> X = data[['size', 'bedrooms', 'age']]  # 假设这三个特征
> y = data['price']
> 
> # 划分训练集和测试集
> X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
> 
> # 初始化线性回归模型
> model = LinearRegression()
> 
> # 训练模型
> model.fit(X_train, y_train)
> 
> # 预测
> y_pred = model.predict(X_test)
> 
> # 评估模型
> mse = mean_squared_error(y_test, y_pred)
> r2 = r2_score(y_test, y_pred)
> 
> print(f'Mean Squared Error: {mse}')
> print(f'R² Score: {r2}')
> ```
>
> ### 总结
>
> 回归问题在机器学习中是一类重要的任务，用于预测连续的数值输出。理解回归问题的核心概念和常见算法有助于在实际应用中选择和实现合适的模型，以解决各种实际问题。通过选择合适的评价指标，可以有效地评估模型的性能并进行优化。

### 思维链(chain of thought)

## Embedding(嵌入)

[OpenAI: Embeddings](https://platform.openai.com/docs/guides/embeddings)

> Turn text into numbers

### 定义(多维解释)

> [!Note]
>
> OpenAI: **Embedding（嵌入向量）** 是一种将高维数据（如文本、图像等）转换为低维向量的技术，以便计算机可以更高效地处理和理解这些数据。Embeddings的核心思想是将复杂的数据映射到一个固定大小的向量空间中，且这些向量空间中的相似性可以反映数据之间的语义相似性。

#### Cloudflare

> [Clouadflare: What are embeddings in machine learning?](https://www.cloudflare.com/learning/ai/what-are-embeddings/) 
>
> Embeddings represent real-world objects, like words, images, or videos, in a form that computers can process. Embeddings enable similarity searches and are foundational for AI.

### 性质与特性



### 相关概念

**1. 向量空间（Vector Space）** 向量空间是Embedding映射后的结果。在这个空间中，每个对象（如一个单词或图像）都表示为一个多维向量，这些向量的维度通常远小于原始数据的维度。向量之间的距离和方向可以反映对象之间的关系和相似性。

**2. 维度（Dimensionality）** Embedding向量的维度是指该向量所包含的元素个数。例如，一个300维的向量就有300个元素。选择合适的维度大小至关重要，维度太低可能导致信息丢失，而维度太高则可能导致计算效率低下。

**3. 语义相似性（Semantic Similarity）** Embedding的一个重要特性是向量之间的距离能够表示语义上的相似性。比如，在文本处理中，两个含义相似的单词会映射到相近的向量上。常用的度量方式有余弦相似性（Cosine Similarity）、欧几里得距离等。

### 应用场景

**1. 文本相似度计算** 通过Embedding将文本转换为向量后，可以计算两个文本之间的相似性，用于推荐系统、信息检索等应用。

**2. 分类与聚类** Embedding可以将数据转化为结构化的向量表示，使得传统的机器学习算法（如SVM、KNN等）能够直接应用于这些低维向量，从而进行分类和聚类。

**3. 生成模型** 在生成对抗网络（GANs）或变分自编码器（VAEs）中，Embedding被用来将离散数据（如文本或图像）映射到连续的潜在空间中，这有助于生成新样本。

## Prompt

[](AI-Prompt.md#Glossary)

- 思维链(chain of thought)

## Topics

### NLP

•自然语言处理（Natural Language Processing），以任务描述的研究领域大语言模型是一种特殊的自然语言处理模型



### GPT

进化之路 AI-NLP-LLM-GPT, 这个过程都涉及到机器学习

#### 多维解释

- 通过机器学习预测关键词出现概率
  - 
  - 示例: 对于`教室里___` 预测: 教室里有桌子, 教室里上课, ~~教室里打高尔夫~~.  明显高尔夫是不对的

## Data Processing

- 数据挖掘
- 数据监管(data curation)

## Vector

### KNN

> 相关概念 `相似度检索` `相似度算法` `近似度检索`

- [IBM: What is KNN](https://www.ibm.com/topics/knn)

The k-nearest neighbors (KNN) algorithm is a non-parametric, supervised learning classifier, which uses proximity to make classifications or predictions about the grouping of an individual data point. It is one of the popular and simplest classification and regression classifiers used in machine learning today.

相关

> [!tip]
>
> K-nearest neighbors (KNN) 是一种简单且常用的监督学习算法，广泛应用于分类和回归问题中。以下是对 KNN 算法的详解：
>
> ## 核心概念
>
> ### 1. 基本原理
>
> KNN 算法基于“相似的对象具有相似的特性”的假设。它通过查找训练样本中与待分类（或回归）样本最相似的 K 个实例，利用这些实例的标签进行预测。具体步骤如下：
>
> 1. 计算待预测样本与训练样本集中每个样本的距离。
> 2. 按照距离升序排列，选择距离最近的 K 个样本。
> 3. 对于分类问题，采用这 K 个样本的标签进行投票，选择票数最多的标签作为预测结果。对于回归问题，计算这 K 个样本的平均值作为预测结果。
>
> ### 2. 距离度量
>
> KNN 算法通常使用以下几种距离度量方法：
>
> - 欧氏距离（Euclidean Distance）
> - 曼哈顿距离（Manhattan Distance）
> - 闵可夫斯基距离（Minkowski Distance）
> - 余弦相似度（Cosine Similarity）
>
> ### 3. 参数选择
>
> - K 值的选择：K 值过小可能导致过拟合，过大可能导致欠拟合。常用的方法是通过交叉验证选择最优的 K 值。
> - 距离度量的选择：不同的距离度量对结果有不同的影响，根据具体问题选择适当的距离度量。
>
> ### 4. 优缺点
>
> - 优点：简单易实现，不需要训练过程，对少量数据和低维数据效果较好。
> - 缺点：计算复杂度高，对大规模数据和高维数据不适用，易受噪声影响。





## 词汇

- 嵌入(embed)
- 扩散(diffusion)
- 潜(latent diffusion)
- 蒸馏()
- Latent Consistency Models, LCM
- 回归(Regression)
    - 人工智能和机器学习领域，回归问题（Regression）是一类主要任务，旨在预测一个连续数值变量的输出。回归问题与分类问题相对，分类问题预测的是离散标签或类别，而回归问题预测的是连续的数值。以下是对回归问题的详解：

- 分类()

## CV

### 参考资料

- https://blog.roboflow.com/glossary/
- https://encord.com/blog/computer-vision-terms/
- https://www.intel.com/content/www/us/en/developer/articles/technical/computer-vision-glossary-of-vocabulary-and-concepts.html

### 图像标注(image annotation)

也称image labeling



### 图像分割(image segmentation)

- https://www.tensorflow.org/tutorials/images/segmentation?hl=zh-cn

### 对象检测(data detection)



### 数据增强(data augmentation)

https://www.tensorflow.org/tutorials/images/data_augmentation?hl=zh-cn



### COCO



### YOLO



# Topics

## CLIP

![CLIP.png:https://github.com/openai/CLIP/blob/main/CLIP.png?raw=true](https://wwfyde.oss-cn-hangzhou.aliyuncs.com/images/202408051456193.png)

# Papers

## Generative Agents：Interactive Simulacra of Human Behavior

生成式智能体：人类行为的交互式模拟

### 参考资料

- [arxiv原文地址](https://arxiv.org/abs/2304.03442)
- [GitHub--Generative Agents：Interactive Simulacra of Human Behavior](https://github.com/joonspk-research/generative_agents)



## Attention is All You Need

### 参考资料

- [公众号文章: Attention Is All You Need (Transformer) 论文精读](https://mp.weixin.qq.com/s/sU2uK2kQVJxzXeVNTmvfYg)



# **学习**



## 核心知识

- 损失函数

- 优化函数
    - 梯度下降
- 优化算法
    - SGD
    - Adam
    - RMSProp



# 机器学习基础

## 人工智能

侯哥: 逻辑性  + 业务理解能力

侯哥-机器学习笔记

YOLO :图像识别

理解原理, 使用API

## 人工智能的多维解释

- 人工智能是一种新的思维方式, 将一些认知问题交给人工智能来处理
- AI is talking about machine-learning models that can learn to make a prediction based on data. 
    通过基于数据学习并做出预测的机器学习模型
    - 通过预训练机器学习模型创建新的数据


## 机器学习相关概念

### 人工智能

> AI - Artificial Intelligence 

定义1: 人工智能就是要让机器的行为看起来就像是人所表现出的智能行为一样(1956达特茅斯回忆)

定义2: 用机器来模仿人类学习以及其他方面的智能

定义3: 研究、开发用于模拟、延伸和扩展人的智能的理论、方法、技术及应用系统的一门新的技术科学

AI的核心问题包括建构能够跟人类似甚至超卓的推理、知识、规划、学习、交流、感知、移物、使用工具和操控机械的能力等

**主要分支**

- 计算机视觉(CV: computer vision)
- 自然语言处理(NLP):文本挖掘和分类(标签)
- 语音识别
- 机器翻译
- 机器人



**人工智能发展必备三要素**：数据、算法、计算力



**GPU与 CPU**：

GPU 加速计算可以将应用程序**计算密集部分**的工作负载转移到 GPU，同时仍由 CPU 运行其余程序代码。**从用户的角度来看，应用程序的运行速度明显加快.**

CPU：由专为顺序串行处理而优化的几个核心组成，而 GPU 则拥有一个由**数以千计的更小、更高效的核心**（专为同时处理多重任务而设计）组成的大规模并行计算架构.

**CPU**需要很强的通用性来处理各种不同的数据类型，同时又要逻辑判断又会引入大量的分支跳转和中断的处理。**这些都使得CPU的内部结构异常复杂。而**GPU**面对的则是类型高度统一的、相互无依赖的大规模数据和不需要被打断的纯净的计算环境**。GPU采用了数量众多的计算单元和超长的流水线，但只有非常简单的控制逻辑并省去了Cache。而CPU不仅被Cache占据了大量空间，而且还有复杂的控制逻辑和诸多优化电路，相比之下计算能力只是CPU很小的一部分.

CPU适用于IO密集型，GPU适用于计算密集型

**提问：什么类型的程序适合在GPU上运行？**

（1）**计算密集型的程序。**所谓计算密集型(Compute-intensive)的程序，就是其大部分运行时间花在了寄存器运算上，寄存器的速度和处理器的速度相当，从寄存器读写数据几乎没有延时。可以做一下对比，读内存的延迟大概是几百个时钟周期；读硬盘的速度就不说了，即便是SSD, 也实在是太慢了。　　

（2）**易于并行的程序。**GPU其实是一种SIMD(Single Instruction Multiple Data)架构， 他有成百上千个核，每一个核在同一时间最好能做同样的事情。

### 机器学习

> Machine Learning	

定义1:机器学习是从**数据**中**自动分析获得模型**，并利用**模型**对未知数据进行预测。

**人工智能和机器学习，深度学习的关系**

​	机器学习是人工智能的一个实现途径

​	深度学习是机器学习的一个方法发展而来

### 特征工程

特征工程是使用**专业背景知识和技巧处理数据**，**使得特征能在机器学习算法上发挥更好的作用的过程**。

意义：会直接影响机器学习的效果

吴恩达: 数据和特征决定了机器学习的上限，而模型和算法只是逼近这个上限而已。

Andrew Ng: Coming up with features is difficult, time-consuming, requires expert knowledge. “Applied machine learning” is basically feature engineering.

### 提示工程Prompt Engineering

### 逻辑

> 推理 logic

逻辑通常可分为三个部分：[归纳推理](https://zh.wikipedia.org/wiki/归纳推理)、[溯因推理](https://zh.wikipedia.org/wiki/溯因推理)和[演绎推理](https://zh.wikipedia.org/wiki/演绎推理)。

**归纳推理**: 是由个别到一般的推理方法。是论证的前提支持结论但不确保结论的推理过程。它基于对特殊的代表（token）的有限观察，把性质或关系归结到类型；或基于对反复再现的现象的模式（pattern）的有限观察，公式表达规律。

**溯因推理**: 是推理（结果）到最佳解释（原因）的过程。**把事实当做结果**，换句话说，它是开始于事实的集合，并推导出其最佳解释的推理过程。有时使用术语 **溯因**(abduction)意味生成假设来解释观察或结论.

**演绎推理**: 是原因到结果的推导。**把事实当做原因**，从一般性的前提出发，通过推导即“演绎”，得出具体陈述或个别结论的过程。演绎推理要求大前提，小前提必须为真

​	定义1：由一般到特殊的推理方法。推论前提与结论之间的联系是必然的，是一种确实性推理。

​	定义2：前提和结论之间具有必然联系的推理

​	定义3：前提蕴涵结论的推理

​	定义4：演绎推理就是前提与结论之间具有充分条件或充分必要条件联系的必然性推理

#### 溯因与演绎的区别

溯因推理: 允许推导 **原因** 作为 **结果** 的结论, 溯因是**解释**已知事物的过程，目标是解释原因(现象)

演绎推理: 允许推导 **结果** 作为 **原因** 的结论, 演绎是**推导**已知事物的推论，目标是得出结论(原理)

在数学里，逻辑是指形式逻辑和数理逻辑，形式逻辑是研究某个形式语言的有效推论。主要是演绎推理。数理逻辑是研究抽象逻辑关系和数	学基本的问题。

#### 归纳与演绎的区别

> 两种的目标都是为了得出某种结论,是两种不同的方法论. 多数人学习的[形式逻辑](https://zh.wikipedia.org/wiki/形式逻辑)是演绎的而不是归纳的。相对于演绎推理，归纳推理达成的结论并非必然与最初的假定有相同的确定程度。
>
> **演绎推理** 区别于 **溯因推理** 和 **归纳推理** ：它们的前提可以预测出高概率的结论，但是不确保结论为真。

**归纳**: 由个别到一般的推理. 用于解决和预测不确定性问题.从特殊归纳出普遍。结论明显不是确定的,前提原因到结果具有普遍性. 

**演绎**: 由一般到特殊的推理. 用于确定性推理.由一般推导出特殊. 结论是一般是确定的, 前提是原因到结果有确定联系.原因和结果都具有确定性



其他区别:

- **思维进程不同**。归纳推理的思维进程是从个别到一般，而演绎推理的思维进程不是从个别到一般，是一个必然地得出的思维进程。
- **对前提真实性的要求不同。**演绎推理要求大前提，小前提必须为真。归纳推理则没有这个要求。
- **结论所断定的知识范围不同。**演绎推理的结论没有超出前提所断定的知识范围。归纳推理除了完全归纳推理，结论都超出了前提所断定的知识范围。
- **前提与结论间的联系程度不同。**演绎推理的前提与结论间的联系是必然的，也就是说，前提真实，推理形式正确，结论就必然是真的。归纳推理除了完全归纳推理前提与结论间的联系是必然的外，前提和结论间的联系都是或然的，也就是说，前提真实，推理形式也正确，但不能必然推出真实的结论。

联系

1，演绎推理如果要以一般性知识为前提，（演绎推理未必都要以一般性知识为前提）则通常要依赖归纳推理来提供一般性知识。

2，归纳推理离不开演绎推理。

#### 逻辑学基本原理

[同一律](https://zh.wikipedia.org/wiki/同一律)（the law of identity）

事物跟其自身相等同，“自己”不能“不是自己”。

[无矛盾律](https://zh.wikipedia.org/wiki/无矛盾律)（the law of non-contradiction）

事物不能同时“是”跟“不是”。是就是，不是就不是。

[排中律](https://zh.wikipedia.org/wiki/排中律)（the law of excluded middle）

事物只能有“是”或“不是”两种状态，不存在其他中间状态。

[充足理由律](https://zh.wikipedia.org/wiki/充足理由律)（the law of sufficient reason）

任何事物都有其存在的充足理由。

## 机器学习工作流程

### 学习目标

[了解机器学习定义](#机器学习)

了解机器学习的工作流程

行 -  样本 列 -- 特征 

数据处理 和特征工程  非常重要

### 工作流程总结

1. 获取数据
2. 数据基本处理
3. 特征工程
4. 机器学习(模型训练)
5. 模型评估

#### 1. 获取到的数据集 

##### 在数据集中一般:

- 一行数据我们称为一个 **样本**
- 一列数据我们称为一个 **特征**
- 有些数据有 **目标值(标签值)** , 有些数据没有目标值

##### 数据类型构成

- 数据类型一: 特征值 + 目标值(连续和离散)

- 数据类型二: 只有特征值, 没有目标值

##### 数据分割

- 机器学习一般的数据集会划分为两个部分: 
    - 训练数据(70-80%): 用于训练, **构建模型**
    - 测试数据(20-30%): 在模型检验时使用, 用于 **评估模型是否有效**

#### 2. 数据基本处理

即对数据进行缺失值, 去除异常值等处理. 数据清洗

#### 3. 特征工程

[特征工程简介](#特征工程)

特征工程包含的内容: 特征提取, 特征预处理, 特征降维

##### 特征提取

特征提取: 将任意数据(如文本或图像)转换为可用于机器学习的数字特征

![特征提取](https://wwfyde.oss-cn-hangzhou.aliyuncs.com/images/202409020010973.png)

##### 特征预处理

特征与处理: 通过**一些转换函数**将特征数据**转换成更加适合算法模型**的特征数据过程

![特征预处理](https://wwfyde.oss-cn-hangzhou.aliyuncs.com/images/202409020011026.png)

##### 特征降维

特征降维: 指在某些限定条件下，**降低随机变量(特征)个数**，得到**一组“不相关”主变量**的过程

![特征降维](https://wwfyde.oss-cn-hangzhou.aliyuncs.com/images/202409020011036.png)

#### 4. **机器学习**

机器学习: 选择合适的算法对模型进行训练

#### 5. **模型评估**

模型评估: 对训练好的模型进行评估

### 完整机器学习项目流程

**1** **抽象成数学问题**

明确问题是进行机器学习的第一步。机器学习的训练过程通常都是一件非常耗时的事情，胡乱尝试时间成本是非常高的。

这里的抽象成数学问题，指的明确我们可以获得什么样的数据，抽象出的问题，是一个分类还是回归或者是聚类的问题。

**2** **获取数据**

数据决定了机器学习结果的上限，而算法只是尽可能逼近这个上限。

数据要有代表性，否则必然会过拟合。

而且对于分类问题，数据偏斜不能过于严重，不同类别的数据数量不要有数量级的差距。

而且还要对数据的量级有一个评估，多少个样本，多少个特征，可以估算出其对内存的消耗程度，判断训练过程中内存是否能够放得下。如果放不下就得考虑改进算法或者使用一些降维的技巧了。如果数据量实在太大，那就要考虑分布式了。

**3** **特征预处理与特征选择**

良好的数据要能够提取出良好的特征才能真正发挥作用。

特征预处理、数据清洗是很关键的步骤，往往能够使得算法的效果和性能得到显著提高。归一化、离散化、因子化、缺失值处理、去除共线性等，数据挖掘过程中很多时间就花在它们上面。这些工作简单可复制，收益稳定可预期，是机器学习的基础必备步骤。

筛选出显著特征、摒弃非显著特征，需要机器学习工程师反复理解业务。这对很多结果有决定性的影响。特征选择好了，非常简单的算法也能得出良好、稳定的结果。这需要运用特征有效性分析的相关技术，如相关系数、卡方检验、平均互信息、条件熵、后验概率、逻辑回归权重等方法。

**4** **训练模型与调优**

直到这一步才用到我们上面说的算法进行训练。现在很多算法都能够封装成黑盒供人使用。但是真正考验水平的是调整这些算法的（超）参数，使得结果变得更加优良。这需要我们对算法的原理有深入的理解。理解越深入，就越能发现问题的症结，提出良好的调优方案。

**5** **模型诊断**

如何确定模型调优的方向与思路呢？这就需要对模型进行诊断的技术。

过拟合、欠拟合 判断是模型诊断中至关重要的一步。常见的方法如交叉验证，绘制学习曲线等。过拟合的基本调优思路是增加数据量，降低模型复杂度。欠拟合的基本调优思路是提高特征数量和质量，增加模型复杂度。

误差分析 也是机器学习至关重要的步骤。通过观察误差样本全面分析产生误差的原因:是参数的问题还是算法选择的问题，是特征的问题还是数据本身的问题……

诊断后的模型需要进行调优，调优后的新模型需要重新进行诊断，这是一个反复迭代不断逼近的过程，需要不断地尝试， 进而达到最优状态。

**6** **模型融合**

一般来说，模型融合后都能使得效果有一定提升。而且效果很好。

工程上，主要提升算法准确度的方法是分别在模型的前端（特征清洗和预处理，不同的采样模式）与后端（模型融合）上下功夫。因为他们比较标准可复制，效果比较稳定。而直接调参的工作不会很多，毕竟大量数据训练起来太慢了，而且效果难以保证。

**7** **上线运行**

这一部分内容主要跟工程实现的相关性比较大。工程上是结果导向，模型在线上运行的效果直接决定模型的成败。 不单纯包括其准确程度、误差等情况，还包括其运行的速度(时间复杂度)、资源消耗程度（空间复杂度）、稳定性是否可接受。

这些工作流程主要是工程实践上总结出的一些经验。并不是每个项目都包含完整的一个流程。这里的部分只是一个指导性的说明，只有大家自己多实践，多积累项目经验，才会有自己更深刻的认识。

## 机器学习算法分类

> 了解机器学习常用算法的分类

#### 概括

根据数据集组成不同, 可以把机器学习算法分类:

- 监督学习:输入数据有特征有标签, 即有标准答案
    - 回归问题
    - 分类问题
- 无监督学习: 只有特征值, 没有目标值,输入数据有特征无标签, 即无标准答案
- 半监督学习
- 强化学习

#### 监督学习

 -- 有特征值, 有目标值:  基于特征来判断目标的某一特征

**目标值**(标签值):要预测的目标结果

监督学习算法常用来做预测

定义:输入数据时有输入特征值和目标值所组成. 函数的的输出可以是一个连续的值(称为**回归** ), 或是输出是有限个离散值(称为 **分类** )

**得分函数**

##### 回归问题

应用场景: 预测房价, 用户点击, 购买预测, ,根据样本集拟合出一条连续曲线

![回归问题](https://wwfyde.oss-cn-hangzhou.aliyuncs.com/images/202409020011037.png)

##### 分类问题

应用场景: 根据肿瘤特征判断良性还是恶性，得到的是结果是“良性”或者“恶性”，是离散的。

![分类问题](https://wwfyde.oss-cn-hangzhou.aliyuncs.com/images/202409020011040.png)

#### 无监督学习

无监督学习: 输入数据是由输入特征值组成

输入数据没有被标记, 也没有确定的结果. 样本数据类别未知，需要根据样本间的相似性对样本集进行分类（聚类，clustering）试图使类内差距最小化，类间差距最大化。

用来训练和学习, 有时候联目标是什么都不知道, 智能通过特征来预测是哪一类的

应用场景: 邮件 / 新闻聚类 

![无监督学习](https://wwfyde.oss-cn-hangzhou.aliyuncs.com/images/202409020011048.png)

**有监督无监督算法对比**

监督学习: 研究分类和回归问题, 输入数据有特征有标签, 即有标准答案

无监督学习: 研究聚类	`	问题, 输入数据有特征无标签, 即无标准答案

![](https://wwfyde.oss-cn-hangzhou.aliyuncs.com/images/202409020011530.png)

#### 半监督学习

 -- 有特征值, 一部分有目标值

半监督学习：即训练集同时包含有标记样本数据和未标记样本数据。

#### 强化学习

> 动态过程, 上一步数据的输出, 是下一步数据的输入

强化学习：实质是，make decisions 问题，即自动进行决策，并且可以做连续决策。

应用场景: 动态系统, 机器人控制

举例：

小孩想要走路，但在这之前，他需要先站起来，站起来之后还要保持平衡，接下来还要先迈出一条腿，是左腿还是右腿，迈出一步后还要迈出下一步。

小孩就是 **agent**，他试图通过采取**行动**（即行走）来操纵**环境**（行走的表面），并且从**一个状态转变到另一个状态**（即他走的每一步），当他完成任务的子任务（即走了几步）时，孩子得到**奖励**（给巧克力吃），并且当他不能走路时，就不会给巧克力。

四要素: agent, action, environment, reward

![强化学习抽象](https://wwfyde.oss-cn-hangzhou.aliyuncs.com/images/202409020011574.png)

强化学习的目标就是**获得最多的累计奖励**。

监督学习和强化学习的对比

|          | **监督学习**                                                 | **强化学习**                                                 |
| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 反馈映射 | 输入到输出的一个映射，监督式学习输出的是之间的关系，可以告诉算法什么样的输入对应着什么样的输出。 | 输入到输出的一个映射，强化学习输出的是给机器的反馈 reward function，即用来判断这个行为是好是坏。 |
| 反馈时间 | 做了比较坏的选择会立刻反馈给算法。                           | 结果反馈有延时，有时候可能需要走了很多步以后才知道以前的某一步的选择是好还是坏。 |
| 输入特征 | 输入是独立同分布的。                                         | 面对的输入总是在变化，每当算法做出一个行为，它影响下一次决策的输入。 |
| 行为模式 | 不考虑行为间的平衡，只是开发（exploitation）。               | 一个 agent 可以在探索和开发（exploration and exploitation）之间做权衡，并且选择一个最大的回报。 |

![alpha zero](https://wwfyde.oss-cn-hangzhou.aliyuncs.com/images/202409020011614.png)

拓展阅读：Alphago进化史 漫画告诉你Zero为什么这么牛http://sports.sina.com.cn/chess/weiqi/2017-10-21/doc-ifymyyxw4023875.shtml

### 机器学习算法分类

- **监督学习(supervised learning)（预测）**

    - 定义：输入数据是由输入特征值和目标值所组成。函数的输出可以是一个连续的值(称为回归），或是输出是有限个离散值（称作分类）。

    - In：有标签，Out：有反馈

        目的：预测结果

        案例：猫狗分类，房价预测

    - **分类 k-近邻算法、贝叶斯分类、决策树与随机森林、逻辑回归、神经网络**

    - **回归 线性回归、岭回归**

- **无监督学习(unsupervised learning)**

    - 定义：输入数据是由输入特征值所组成。

    - In：无标签，Out：无反馈

        目的：发现潜在结构

        案例：“物以类聚，人以群分”

    - **聚类 k-means**，**降维**

- **半监督学习**

    - 已知：训练样本Data和待分类的类别

        未知：训练样本有无标签均可

        应用（案例）：训练数据量过多时，

        监督学习效果不能满足需求，因此用来增强效果。

- **强化学习**

    - In：决策流程及激励系统，Out：一系列行动

        目的：长期利益最大化，回报函数（只会提示你是否在朝着目标方向前进的延迟反映）

        案例：学下棋

        **算法：马尔科夫决策，动态规划**

## 模型评估

> 了解机器学习中模型评估的方法
>
> 知道过拟合, 欠拟合发生情况

模型评估是模型开发过程不可或缺的一部分。它有助于发现表达数据的最佳模型和所选模型将来工作的性能如何。**按照数据集的目标值不同，可以把模型评估分为分类模型评估和回归模型评估。**

### 分类模型评估

- 准确率
    - 预测正确的数占样本总数的比例。
- 精确率
    - 正确预测为正占**全部预测为正**的比例
- 召回率
    - 正确预测为正占**全部正样本**的比例
- F1-score
    - 主要用于评估模型的稳健性
- AUC指标
    - 主要用于评估样本不均衡的情况

### 回归模型评估

![image-20190218152834380](https://wwfyde.oss-cn-hangzhou.aliyuncs.com/images/202409020011648.png)

- ##### 均方根误差（Root Mean Squared Error，RMSE）

    - RMSE是一个衡量回归模型误差率的常用公式。 然而，它仅能比较误差是相同单位的模型。

        ![image-20190312193846308](https://wwfyde.oss-cn-hangzhou.aliyuncs.com/images/202409020011683.png)

- ##### 相对平方误差（Relative Squared Error，RSE）

    - 与RMSE不同，RSE可以比较误差是不同单位的模型。

        ![image-20190312194839069](https://wwfyde.oss-cn-hangzhou.aliyuncs.com/images/202409020011716.png)

- ##### 平均绝对误差（Mean Absolute Error，MAE)

    - MAE与原始数据单位相同， 它仅能比较误差是相同单位的模型。量级近似与RMSE，但是误差值相对小一些。

        ![image-20190312194923850](https://wwfyde.oss-cn-hangzhou.aliyuncs.com/images/202409020011898.png)

- ##### 相对绝对误差（Relative Absolute Error，RAE)

    - 与RSE不同，RAE可以比较误差是不同单位的模型。

        ![image-20190312195006252](https://wwfyde.oss-cn-hangzhou.aliyuncs.com/images/202409020011933.png)

- ##### 决定系数 (Coefficient of Determination)

    - 决定系数 (**R2**)回归模型汇总了回归模型的解释度，由平方和术语计算而得。

        ![image-20190312202620606](https://wwfyde.oss-cn-hangzhou.aliyuncs.com/images/202409020011970.jpeg)

    - R2描述了回归模型所解释的因变量方差在总方差中的比例。R2很大，即自变量和因变量之间存在线性关系，如果回归模型是“完美的”，SSE为零，则R2为1。R2小，则自变量和因变量之间存在线性关系的证据不令人信服。如果回归模型完全失败，SSE等于SST，没有方差可被回归解释，则R2为零。

### 拟合

模型评估用于评价训练好的的模型的表现效果，其表现效果大致可以分为两类：过拟合、欠拟合。

在训练过程中，你可能会遇到如下问题：

##### 训练数据训练的很好啊，误差也不大，为什么在测试集上面有问题呢？

当算法在某个数据集当中出现这种情况，可能就出现了拟合问题。

### 欠拟合

![image-20190312213119759](https://wwfyde.oss-cn-hangzhou.aliyuncs.com/images/202409020011997.jpeg)

因为机器学习到的天鹅特征太少了，导致区分标准太粗糙，不能准确识别出天鹅。

### 过拟合

![è¿‡æ‹Ÿåˆ](https://wwfyde.oss-cn-hangzhou.aliyuncs.com/images/202409020011030.png)

机器已经基本能区别天鹅和其他动物了。然后，很不巧已有的天鹅图片全是白天鹅的，于是机器经过学习后，会认为天鹅的羽毛都是白的，以后看到羽毛是黑的天鹅就会认为那不是天鹅。

**过拟合**（over-fitting）：所建的机器学习模型或者是深度学习模型在训练样本中表现得过于优越，导致在验证数据集以及测试数据集中表现不佳。

### 小结

- 分类模型评估【知道】
    - 精确率 -- 查的准
    - 召回率 -- 查的全
    - F1-score -- 评判模型的稳健性
- 回归模型评估【知道】
    - MSE -- 均方误差
    - RMSE -- 均方根误差
    - MAE -- 平方绝对误差
- 拟合【掌握】
    - 举例 -- 判断是否是人
    - 欠拟合
        - 学习到的东西太少
        - 学习到的特征少
    - 过拟合
        - 学习到的东西太多
        - 学习到的特征多，不好泛化



## 深度学习

 --由神经网络发展而来



## 机器学习基础环境安装与使用

```
jupyter notebook

matplotlib

numpy

pandas

tables

bokeh -散景

Seaborn 
```



## Matplotlib

#### 学习目标

- Matplotlib的架构
- 应用Matplotlib的基本功能实现图形显示
- 应用Matplotlib实现多图显示
- 应用Matplotlib实现不同画图种类

#### 参考文档

中文文档

官方文档

[解决中文乱码问题](https://blog.csdn.net/GreenHandCGL/article/details/79814572)

```
解决中文乱码问题
venv\Lib\site-packages\matplotlib\mpl-data\matplotlibrc
修改文件, 取消注释font.family和font.sans-serif
并且在font.sans-serif中添加上自己想要的字体
```



#### 说明简介

专门用于开发2D图表(包括3D图表), 使用起来极其简单, 以渐进交互式方式实现数据可视化

**作用**: 可视化是在整个数据挖掘的关键辅助工具, 可以清晰的理解数据, 从而调整我们的分析方法. 能将数据进行可视化, 更直观的呈现, 使数据更加客观, 更具说服力

#### 用法示例

实现一个最简单的画图功能: 基本思路是

```python
# 导入画图模块
import matplotlib.pyplot as plt

# 创建画布
plt.figure(figsize=(20,9), dpi=125)

# 绘制图像
x = [1, 2, 3]
y = [4, 5, 6]
plt.plot(x, y)

# 显示图像
plt.show()
```

![简单绘图](https://wwfyde.oss-cn-hangzhou.aliyuncs.com/images/202409020011083.png)

### matplotlib结构

![图像结构](https://wwfyde.oss-cn-hangzhou.aliyuncs.com/images/202409020011188.png)

#### 容器层

容器层主要由Canvas、Figure、Axes组成。

一个figure(图像)可以包含多个axes(坐标系/绘图区)，但是一个axes只能属于一个figure。

一个axes(坐标系/绘图区)可以包含多个axis(坐标轴)，包含两个即为2d坐标系，3个即为3d坐标系 

![](https://wwfyde.oss-cn-hangzhou.aliyuncs.com/images/202409020011246.png)

##### Canvas - 画板

Canvas是位于最底层的系统层，在绘图的过程中充当画板的角色，即放置画布(Figure)的工具。

##### Figure - 画布

Figure是Canvas上方的第一层，也是需要**用户来操作**的应用层的第一层，在绘图的过程中充当画布的角色。

Figure:指整个图形(可以通过plt.figure()设置画布的大小和分辨率等)

##### Axes - 坐标系

Axes是应用层的第二层，在绘图的过程中相当于画布上的绘图区的角色。

Axes(**坐标系**):数据的绘图区域

Axis(**坐标轴**)：坐标系中的一条轴，包含大小限制、刻度和刻度标签

#### 辅助显示层

辅助显示层为Axes(绘图区)内的除了根据数据绘制出的图像以外的内容，主要包括Axes外观(facecolor)、边框线(spines)、坐标轴(axis)、坐标轴名称(axis label)、坐标轴刻度(tick)、坐标轴刻度标签(tick label)、网格线(grid)、图例(legend)、标题(title)等内容。

该层的设置可使图像显示更加直观更加容易被用户理解，但又不会对图像产生实质的影响。

![辅助显示层](https://wwfyde.oss-cn-hangzhou.aliyuncs.com/images/202409020011297.png)

#### 图像层

图像层指Axes内通过plot、scatter、bar、histogram、pie等函数根据数据绘制出的图像

#### 总结

- Canvas（画板）位于最底层，用户一般接触不到
- Figure（画布）建立在Canvas之上
- Axes（绘图区）建立在Figure之上
- 坐标轴（axis）、图例（legend）等辅助显示层以及图像层都是建立在Axes之上

### 折线图(plot)与基础绘图功能

#### 学习目标

- 学习折线图的绘制和图形保存
- 给图形添加辅助功能(如：标注、x,y轴名称、标题等)
- 多次plot绘制图形
- 多个坐标系显示图形
- 知道折线图的应用场景



#### 绘图顺序

导入需要的包 >> 创建画布 >> 绘制图像 >>辅助显示 >> 显示图像

#### 折线图绘制与显示

matplotlib.pytplot包含了一系列类似于matlab的画图函数。 它的函数**作用于当前图形(figure)的当前坐标系(axes)**。

```python
# 导入画图模块
import matplotlib.pyplot as plt

# 1.创建画布(容器层)
plt.figure(figsize=(10, 10))

# 2.绘制折线图(图像层)
plt.plot([1, 2, 3, 4, 5, 6 ,7], [17,17,18,15,11,11,13])

# 3.显示图像
plt.show()

```

#### 设置画布属性与图片保存

```
plt.figure(figsize=(), dpi=)
    figsize:指定图的长宽
    dpi:图像的清晰度
    返回fig对象
plt.savefig(path)

```

```python
# 1.创建画布，并设置画布属性
plt.figure(figsize=(20, 8), dpi=80)
# 2.保存图片到指定路径
plt.savefig("test.png")
```

注意：plt.show()会释放figure资源，如果在显示图像之后保存图片将只能保存空图片。

#### 完善原始折线图

**案例：显示温度变化状况**

需求：画出某城市11点到12点1小时内每分钟的温度变化折线图，温度范围在15度~18度

效果：

![上海1](https://wwfyde.oss-cn-hangzhou.aliyuncs.com/images/202409020011336.png)

#### 准备数据并画出初始折线图 

```python
# 画出温度变化图
import matplotlib.pyplot as plt
import random

# 0.准备x, y坐标的数据
x = range(60)
y_shanghai = [random.uniform(15, 18) for i in x]

# 1.创建画布
plt.figure(figsize=(20, 8), dpi=80)

# 2.绘制折线图
plt.plot(x, y_shanghai)

# 3.显示图像
plt.show()
```

![上海2](https://wwfyde.oss-cn-hangzhou.aliyuncs.com/images/202409020011420.png)

#### 添加自定义x,y刻度

```python
# 使用方法
plt.xticks(ticks=None, labels=None, **kwargs)
plt.yticks(ticks=None, labels=None, **kwargs)
# ticks:要显示的刻度值
# labels:显示的标签
```

```python
# 增加以下两行代码
# 构造x轴刻度标签
x_ticks_label = ["11点{}分".format(i) for i in x]
# 构造y轴刻度
y_ticks = range(40)

# 修改x,y轴坐标的刻度显示
plt.xticks(x[::5], x_ticks_label[::5])
plt.yticks(y_ticks[::5])
```

```python
# 绘制温度图
import matplotlib.pyplot as plt
import random


plt.figure(figsize=(16,9), dpi=150)

x = range(60)

y = [random.uniform(15, 18) for i in x]

y_beijing = [random.uniform(9,12) for i in x] 

# 修改x, y轴坐标的刻度显示
x_ticks_label = [f"11: {i:02d}" for i in x]

y_ticks = range(40)

plt.xticks(x[::5], x_ticks_label[::5])
# plt.yticks(y_ticks[::5])

# 添加网格显示
plt.grid(True, linestyle='--', alpha=0.5)

# 添加描述信息
plt.xlabel("时间")
plt.ylabel("温度")
plt.title("温度变化显示图")

plt.plot(x, y, label="上海")

# 使用多次plot可以画多个折线
plt.plot(x, y_beijing, color='r', linestyle='--', label="北京")

# 显示图例
plt.legend(loc="best")


plt.savefig("../../wwfyde/Markdown/images/Python机器学习/温度折线图.png")
plt.show()
```

![温度折线图](https://wwfyde.oss-cn-hangzhou.aliyuncs.com/images/202409020011458.png)

#### 添加网格显示

为了更加清楚地观察图形对应的值

```python
plt.grid(True, linestyle='--', alpha=0.5)
```

#### 添加描述信息

添加x轴、y轴描述信息及标题

```python
plt.xlabel("时间")
plt.ylabel("温度")
plt.title("中午11点0分到12点之间的温度变化图示")
```

#### 多次plot

需求：再添加一个城市的温度变化

收集到北京当天温度变化情况，温度在1度到3度。怎么去添加另一个在同一坐标系当中的不同图形，**其实很简单只需要再次plot即可**，但是需要区分线条，如下显示

#### 设置图形风格

| color  |   linestyle    |
| :----: | :------------: |
| r 红色 |     - 实线     |
| g 绿色 |    - - 虚线    |
| b 蓝色 |   -. 点划线    |
| w 白色 |    : 点虚线    |
| c 青色 | ' ' 留空、空格 |
| m 洋红 |                |
| y 黄色 |                |
| k 黑色 |                |

**显示图例**

注意：如果只在plt.plot()中设置label还不能最终显示出图例，还需要通过plt.legend()将图例显示出来

```
plt.legend(loc="best")
```

![图例显示](https://wwfyde.oss-cn-hangzhou.aliyuncs.com/images/202409020011003.gif)

#### 小结

- 图像保存【知道】
    - plt.savefig("路径")
- 添加x,y轴刻度【知道】
    - plt.xticks()
    - plt.yticks()
    - **注意:在传递进去的第一个参数必须是数字,不能是字符串,如果是字符串吗,需要进行替换操作**
- 添加网格显示【知道】
    - plt.grid(linestyle="--", alpha=0.5)
- 添加描述信息【知道】
    - plt.xlabel()
    - plt.ylabel()
    - plt.title()
- 多次plot【了解】
    - 直接进行添加就OK
- 显示图例【知道】
    - plt.legend(loc="best")
    - **注意:一定要在plt.plot()里面设置一个label,如果不设置,没法显示**
- 多个坐标系显示【了解】
    - plt.subplots(nrows=, ncols=)
- 折线图的应用【知道】
    - 1.应用于观察数据的变化
    - 2.可是画出一些数学函数图像

### 常见图形绘制

#### 学习目标

- 掌握常见统计图及其意义
- 绘制散点图和柱状图
- 探究不同变量之间的关系

Matplotlib能够绘制**折线图、散点图、柱状图、直方图、饼图。**

我们需要知道不同的统计图的意义，以此来决定选择哪种统计图来呈现我们的数据。

#### 常见图形种类及意义

- **折线图**：以折线的上升或下降来表示统计数量的增减变化的统计图

    **特点：能够显示数据的变化趋势，反映事物的变化情况。(变化)**

    api：plt.plot(x, y)

    ![img](https://wwfyde.oss-cn-hangzhou.aliyuncs.com/images/202409020011022.png)

- **散点图：**用两组数据构成多个坐标点，考察坐标点的分布,判断两变量之间是否存在某种关联或总结坐标点的分布模式。

    **特点：判断变量之间是否存在数量关联趋势,展示离群点(分布规律)**

    api：plt.scatter(x, y)

    ![img](https://wwfyde.oss-cn-hangzhou.aliyuncs.com/images/202409020011063.png)

- **柱状图：**排列在工作表的列或行中的数据可以绘制到柱状图中。

    **特点：绘制连离散的数据,能够一眼看出各个数据的大小,比较数据之间的差别。(统计/对比)**

    api：plt.bar(x, width, align='center', **kwargs)

    ```
    Parameters:    
    x : sequence of scalars.
    
    width : scalar or array-like, optional
    柱状图的宽度
    
    align : {‘center’, ‘edge’}, optional, default: ‘center’
    Alignment of the bars to the x coordinates:
    ‘center’: Center the base on the x positions.
    ‘edge’: Align the left edges of the bars with the x positions.
    每个柱状图的位置对齐方式
    
    **kwargs :
    color:选择柱状图的颜色
    ```

    ![img](https://wwfyde.oss-cn-hangzhou.aliyuncs.com/images/202409020011125.png)

- **直方图：**由一系列高度不等的纵向条纹或线段表示数据分布的情况。 一般用横轴表示数据范围，纵轴表示分布情况。

    **特点：绘制连续性的数据展示一组或者多组数据的分布状况(统计)**

    api：matplotlib.pyplot.hist(x, bins=None)

    ```
    Parameters:    
    x : (n,) array or sequence of (n,) arrays
    
    bins : integer or sequence or ‘auto’, optional
    组距
    ```

    ![img](https://wwfyde.oss-cn-hangzhou.aliyuncs.com/images/202409020011196.png)

- **饼图：**用于表示不同分类的占比情况，通过弧度大小来对比各种分类。

    **特点：分类数据的占比情况(占比)**

    api：plt.pie(x, labels=,autopct=,colors)

    ```
    x:数量，自动算百分比
    labels:每部分名称
    autopct:占比显示指定%1.2f%%
    colors:每部分颜色
    ```

    ![](https://wwfyde.oss-cn-hangzhou.aliyuncs.com/images/202409020011263.png)

#### 散点图绘制

需求：探究房屋面积和房屋价格的关系

房屋面积数据：

```python
x = [225.98, 247.07, 253.14, 457.85, 241.58, 301.01,  20.67, 288.64,
       163.56, 120.06, 207.83, 342.75, 147.9 ,  53.06, 224.72,  29.51,
        21.61, 483.21, 245.25, 399.25, 343.35]
```

房屋价格数据：

```python
y = [196.63, 203.88, 210.75, 372.74, 202.41, 247.61,  24.9 , 239.34,
       140.32, 104.15, 176.84, 288.23, 128.79,  49.64, 191.74,  33.1 ,
        30.74, 400.02, 205.35, 330.64, 283.45]
```

![img](https://wwfyde.oss-cn-hangzhou.aliyuncs.com/images/202409020011320.png)

代码：

```python
# 0.准备数据
x = [225.98, 247.07, 253.14, 457.85, 241.58, 301.01,  20.67, 288.64,
       163.56, 120.06, 207.83, 342.75, 147.9 ,  53.06, 224.72,  29.51,
        21.61, 483.21, 245.25, 399.25, 343.35]
y = [196.63, 203.88, 210.75, 372.74, 202.41, 247.61,  24.9 , 239.34,
       140.32, 104.15, 176.84, 288.23, 128.79,  49.64, 191.74,  33.1 ,
        30.74, 400.02, 205.35, 330.64, 283.45]

# 1.创建画布
plt.figure(figsize=(20, 8), dpi=100)

# 2.绘制散点图
plt.scatter(x, y)

# 3.显示图像
plt.show()
```

#### 柱状图绘制

**需求-对比每部电影的票房收入**

电影数据如下图所示：

![电影票房数据](https://wwfyde.oss-cn-hangzhou.aliyuncs.com/images/202409020011401.png)

**1 准备数据**

```
['雷神3：诸神黄昏','正义联盟','东方快车谋杀案','寻梦环游记','全球风暴', '降魔传','追捕','七十七天','密战','狂兽','其它']
[73853,57767,22354,15969,14839,8725,8716,8318,7916,6764,52222]
```

**2 绘制**

- matplotlib.pyplot.bar(x, width, align='center', **kwargs)

绘制柱状图

代码：

```python
# 0.准备数据
# 电影名字
movie_name = ['雷神3：诸神黄昏','正义联盟','东方快车谋杀案','寻梦环游记','全球风暴','降魔传','追捕','七十七天','密战','狂兽','其它']
# 横坐标
x = range(len(movie_name))
# 票房数据
y = [73853,57767,22354,15969,14839,8725,8716,8318,7916,6764,52222]

# 1.创建画布
plt.figure(figsize=(20, 8), dpi=100)

# 2.绘制柱状图
plt.bar(x, y, width=0.5, color=['b','r','g','y','c','m','y','k','c','g','b'])

# 2.1b修改x轴的刻度显示
plt.xticks(x, movie_name)

# 2.2 添加网格显示
plt.grid(linestyle="--", alpha=0.5)

# 2.3 添加标题
plt.title("电影票房收入对比")

# 3.显示图像
plt.show()
```

**参考链接：**

 https://matplotlib.org/index.html

#### 小结

- 折线图【知道】
    - 能够显示数据的变化趋势，反映事物的变化情况。(变化)
    - plt.plot()
- 散点图【知道】
    - 判断变量之间是否存在数量关联趋势,展示离群点(分布规律)
    - plt.scatter()
- 柱状图【知道】
    - 绘制连离散的数据,能够一眼看出各个数据的大小,比较数据之间的差别。(统计/对比)
    - plt.bar(x, width, align="center")
- 直方图【知道】
    - 绘制连续性的数据展示一组或者多组数据的分布状况(统计)
    - plt.hist(x, bins)
- 饼图【知道】
    - 用于表示不同分类的占比情况，通过弧度大小来对比各种分类
    - plt.pie(x, labels, autopct, colors)

## Numpy



## Pandas



DataFrame 类似于Numpy中的二维数组



## 机器学习与深度学习之间有什么区别？

机器学习 (ML) 是训练计算机程序或系统在没有明确指令的情况下执行任务的科学。计算机系统使用机器学习算法来处理大量数据、识别数据模式并预测未知或新场景的准确结果。深度学习是机器学习的一个子集，使用特定的算法结构，称为*神经网络*，以人脑为模型。深度学习方法试图自动执行通常需要人类智能的更复杂的任务。例如，您可以使用深度学习来描述图像、翻译文档或将声音文件转录为文本。





## 机器学习必修数学

主要内容

**机器学习基础**: 机器学习的分类与一般思想

**微积分基础**: 泰勒公式, 导数与梯度

**概率与统计基础**: 概率公式, 常见分布, 常见统计量

**线性代数基础**: 矩阵乘法的集合意义

## 迈向机器学习

机器学习主要解决问题

以大量数据为基础, 预测结果; 对大量数据进行识别和分类.

比较关键的一点是, 预测或分类的具体方法并不是由程序员事先设定的, 而是由计算机从大量数据中自动提取特征, 从而解决问题.

预测问题

分类问题

感知器

加权求和

梯度下降法

神经网络



## 机器学习算法

- Prompt: 深度学习算法有哪些
- 深度学习是一类基于人工神经网络构建的机器学习算法，通常用于处理复杂的大规模数据集。以下是一些常用的深度学习算法：
    1. **多层感知机（Multilayer Perceptron, MLP）**：
        - 是最基本的前馈神经网络，包括一个或多个隐藏层，用于解决分类和回归问题。

    2. **卷积神经网络（Convolutional Neural Network, CNN）**：
        - 主要用于处理图像数据，利用卷积层对输入进行特征提取，通过池化层减少计算量，用于图像分类、物体检测等任务。

    3. **循环神经网络（Recurrent Neural Network, RNN）**：
        - 具有循环连接的神经网络，用于处理序列数据，例如文本、时间序列等，适用于自然语言处理、语音识别等任务。

    4. **长短时记忆网络（Long Short-Term Memory, LSTM）**：
        - 是一类特殊的RNN，通过引入门控机制解决了普通RNN中的梯度消失和梯度爆炸问题，适用于处理长序列数据。

    5. **门控循环单元（Gated Recurrent Unit, GRU）**：
        - 与LSTM类似，也是一种解决RNN中梯度问题的网络结构，但相对于LSTM具有更少的参数。

    6. **生成对抗网络（Generative Adversarial Network, GAN）**：
        - 包括一个生成网络和一个判别网络，通过对抗训练的方式，生成网络可以生成与真实数据相似的样本，适用于生成图像、声音等任务。

    7. **自动编码器（Autoencoder）**：
        - 用于学习数据的低维表示，包括编码器和解码器两部分，常用于降维、特征提取等任务。

    8. **强化学习（Reinforcement Learning, RL）**：
        - 不同于监督学习和无监督学习，强化学习关注的是智能体在环境中通过采取行动来获得奖励，从而学会选择行动以达到最大化奖励。

- 以上列举的是一些常用的深度学习算法，实际上深度学习领域涵盖了更多的模型和技术，如残差网络（Residual Network, ResNet）、注意力机制（Attention Mechanism）、变分自编码器（Variational Autoencoder, VAE）等等。选择合适的算法取决于具体的任务和数据特性。

## 深度学习模型

BERT

GPT 





## 神经网络算法



# 技术与算法概略

## Section1

- 正则化技术



# Neural Network

## 人工神经网络(Artifical Neural Network, ANN)

##   

# OpenAI(LLM)



- [Immersive Translate:understanding-chatgpt——沉浸式翻译:理解ChatGPT](https://www.atmosera.com/blog/understanding-chatgpt/)

## 参考资料

- [AI大模型应用开发实战营大纲](https://u.geekbang.org/subject/llm)
- [AI大模型微调训练营](https://u.geekbang.org/subject/finetuning)
- [AI Glossary](AI.md#Glossary)
- 官方文档和博客
    - [Overview](https://platform.openai.com/docs/overview)
    - [Guide for Prompt Enginerring](https://platform.openai.com/docs/guides/prompt-engineering)

## 多维解释

- 问答机器人, AI助手
- 材料撰写
- 全语种润色
- 策略制定, 录入资料
- 超级个体, 复杂专家的能力
- 演化路径: AI-NLP-LLM-GPT

## Features

- 自然语言检索，真正开始理解文本内容
- 多模态兼容，支持图像、音频、视频等

- 交互式问答，根据使用者水平个性化调整
- 有常识，像“人”一样理解其他数据库、工具
- 大模型本质是概率模型，易出现严重的“幻觉”
- 大模型的回答极“自信”，难分辨**



## Embeddings

[What are embeddings?](https://platform.openai.com/docs/guides/embeddings/what-are-embeddings)

OpenAI’s text embeddings measure the relatedness of text strings. Embeddings are commonly used for:

- **Search** (where results are ranked by relevance to a query string)
- **Clustering** (where text strings are grouped by similarity)
- **Recommendations** (where items with related text strings are recommended)
- **Anomaly detection** (where outliers with little relatedness are identified)
- **Diversity measurement** (where similarity distributions are analyzed)
- **Classification** (where text strings are classified by their most similar label)

An embedding is a vector (list) of floating point numbers. The [distance](https://platform.openai.com/docs/guides/embeddings/which-distance-function-should-i-use) between two vectors measures their relatedness. Small distances suggest high relatedness and large distances suggest low relatedness.

Visit our [pricing page](https://openai.com/api/pricing/) to learn about Embeddings pricing. Requests are billed based on the number of [tokens](https://platform.openai.com/tokenizer) in the [input](https://platform.openai.com/docs/api-reference/embeddings/create#embeddings/create-input).



# 索引

- ChatGPT奇技淫巧
    - 视频总结
- Prompt框架
- 结构化提示词
    - 综合
    - 引导
    - LLM Agent
    - AI Agent : 具有独立思考的
    - 模版
    - 知识库
- ChatGPT效率技巧
- 逆向
- 提示词网站
- 官网
- 提示学习(Prompt Learning)
    - 思维链（Chain-of-Thought, CoT）：开山之作
    - 自洽性（Self-Consistency）：多路径推理
        - 前后一致性, 逻辑冲突
        - 流程, 规则, 本身应该是有一定的模式化
    - 思维树（Tree-of-Thoughts, ToT）：续写佳话
- Agent, 模式
- 流程化, 最佳实践
- **指令**
    - syntax
        - [模版]

# 核心模式-架构思想

- 选择大模型——直接使用
- 测试原生能力——提示词工程
- 链接外部知识的AI——检索增强生成(RAG)——AI备忘录/企业知识库
    - 更适合自然语言处理
- 训练外部知识的AI——训练调优(fine-tuning)——微调大模型/垂直大模型
    - 非自然语言的理解部分, 比如图像
- 理解大模型的工作原理



# 核心原理

注意力机制

# Tuning-微调

微调

## Adapter

## Prefix



## Prompt

- 业务-领域知识, 工程知识, 多维(多角度)解释, 自动化

- 角色(高级/专家)-任务-格式(模版/模式/抽象, 结构-约束-关系)
    - 市场领域专家

- 上下文提及
- 输入-输出
- 输入-上下文, 关键词, 负面词
- 输出模式约束-设定目标
- 自动化
- 思维链(chain of thought, COT)
    - 策略: 将复杂的任务拆分为简单的任务
- 自洽性
- 多角色扮演
- 自我迭代
- GPT
- 提示词高阶技巧
- (驱动索引)
- kayn-领域知识内聚
- 思考路径
- ChatGPT指令模式-instruction 
- GPT builder
- gpts
- 麦肯锡分析方法

## 技巧

- `explain ...`: 解释代码

- `generate comment`: 生成注释

- `generate unittest`: 生成单元测试

- 结构化提示

    - (意义)相近的内容放在一起
    - 解释说明, 声明是语言
    - 需要按照一定的格式
    - 总分总, 列表, 层次, 
    - 人名术语表 `David bohm -> 大卫·玻姆`

    https://www.google.com/search?client=safari&rls=en&q=anthropic&ie=UTF-8&oe=UTF-8

    anthropic

- 使用模版, 关键部分

- 如何写提示词

    - GPT4, claude, 

- API接口

- 

### 用途示例



- 阅读
- 翻译
    - 语句润色

- 提示语
- 延迟更新
- 错误提示, 
- 领域专业术语, 名词解释
    - 定义
    - 用法示例
    - 特性
    - 多维解释
    - 背景提及, 追问
    - 写代码
    - ...如何做
- 专业领域知识库, 行业专家, 上帝模式, 写材料
- 读论文
    - 传递文档进去
    - 传递资源/文件进去
- how-to 指南
- 新技术学习, 助手 Assistant
- 场景模拟

### 负面词

隐藏角色

## P-Tuning



## LoRA



# Agent-智能体

# **OpenAI(LLM)**



## Links

### Articles

- [introduction_to_gpt4o](https://cookbook.openai.com/examples/gpt4o/introduction_to_gpt4o)

## Usage

GPT-4, including its optimized variant GPT-4O, is a powerful and versatile language model developed by OpenAI. Here are some key capabilities of GPT-4O:



​	1.	**Natural Language Understanding and Generation**:

​	•	Understands and generates human-like text based on the input it receives.

​	•	Can carry out conversations, answer questions, and provide detailed explanations on a wide range of topics.

​	2.	**Text Completion and Summarization**:

​	•	Completes partial text inputs coherently.

​	•	Summarizes long texts into concise summaries.

​	3.	**Translation and Multilingual Support**:

​	•	Translates text between multiple languages.

​	•	Understands and responds in various languages.

​	4.	**Creative Writing and Content Creation**:

​	•	Generates creative content such as stories, poems, and essays.

​	•	Assists in writing tasks including blog posts, articles, and social media content.

​	5.	**Programming and Technical Assistance**:

​	•	Generates and explains code in multiple programming languages.

​	•	Provides technical guidance, troubleshooting, and debugging assistance.

​	6.	**Data Analysis and Visualization**:

​	•	Analyzes data and generates insights.

​	•	Creates data visualizations to represent information graphically.

​	7.	**Educational and Tutoring Support**:

​	•	Assists with learning and tutoring in various subjects.

​	•	Provides explanations and answers to academic questions.

​	8.	**Information Retrieval and Research**:

​	•	Retrieves and synthesizes information from a wide range of sources.

​	•	Conducts research on specific topics and provides summarized results.

​	9.	**Conversational AI and Customer Support**:

​	•	Acts as a conversational agent for customer service.

​	•	Handles inquiries, complaints, and provides support in customer interaction scenarios.

​	10.	**Image and Document Analysis**:

​	•	Describes and analyzes the content of images and documents.

​	•	Extracts and interprets textual and visual information from provided media.

​	11.	**Customization and Personalization**:

​	•	Adapts responses based on user preferences and context.

​	•	Remembers user-specific details to provide personalized assistance.

​	12.	**Advanced Reasoning and Problem Solving**:

​	•	Engages in complex reasoning tasks.

​	•	Solves problems that require logical thinking and multi-step processes.



These capabilities make GPT-4O a versatile tool for various applications, from casual conversation and creative writing to technical support and data analysis.



## Techs

- [Prompt Cache](https://platform.openai.com/docs/guides/prompt-caching)



# CV









# Stable Diffusion

## Extensions



# Object Detect



# NLP



# Vector



# RAG

## 最佳实践



## 常见问题

### RAG效果不佳

增加上下文`context`窗口, 提升`TOP-K`值

